{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = {(\"A\", \"B\", \"C\", \"D\"): \"hyperthyroid condition\", (\"E\", \"F\", \"G\", \"H\"): \"hypothyroid condition\", (\"I\", \"J\"): \"binding protein\", (\"K\"): \"general health\", (\"L\", \"M\", \"N\"): \"replacement therapy\",(\"O\", \"P\", \"Q\", \"S\", \"T\"): \"other\",(\"R\"): \"discordant results\", (\"-\"): \"healthy\"}\n",
    "def create_target(verdict):\n",
    "    if len(verdict) == 1:\n",
    "        for key in conditions:\n",
    "            if verdict in key:\n",
    "                return conditions[key]\n",
    "        return \"invalid verdict\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "def dataCreator(targetColumun):\n",
    "    dt = pd.read_csv('proj-data.csv')\n",
    "    dt = dt.replace('?',np.nan)\n",
    "    dt = dt[dt['age:'] <= 120]\n",
    "    dt.loc[(dt['sex:'].isna()) & (dt['pregnant:'] == True), 'sex:'] = 0\n",
    "    mColumns = ['TSH:', 'T3:', 'TT4:', \"T4U:\", \"FTI:\", \"TBG:\"]\n",
    "    dt[\"diagnoses\"] = dt[\"diagnoses\"].apply(create_target)\n",
    "    dt[\"target\"] = dt[targetColumun]\n",
    "    dt = dt.dropna(subset=['sex:'])\n",
    "    dt = dt.drop([targetColumun, \"referral source:\", \"[record identification]\"], axis=1)\n",
    "    dt = dt.replace({ \"f\": 0, \"t\": 1, \"F\":0, \"M\":1})\n",
    "    for column in mColumns:\n",
    "        dt[column] = pd.to_numeric(dt[column], errors='coerce')\n",
    "    numeric_columns = dt.select_dtypes(include=[np.number])\n",
    "    dt[numeric_columns.columns] = numeric_columns.fillna(-1)\n",
    "    return dt\n",
    "def modelCreator(dt, problem_type):\n",
    "    le = LabelEncoder()\n",
    "    X, y = dt.drop(\"target\", axis=1), le.fit_transform(dt[\"target\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "    classification_models = {\"Logistic Regression\": LogisticRegression(max_iter=10000),\"Decision Tree Classifier\": DecisionTreeClassifier(),\"Random Forest Classifier\": RandomForestClassifier(max_depth=15, min_samples_split=2, n_estimators=150, random_state=4),\"SVM\": SVC(),\"KNN Classifier\": KNeighborsClassifier(), \"MLP\": MLPClassifier(max_iter=1000),\"NaiveBayes\": GaussianNB(),\"XGB Classifier\": XGBClassifier(eval_metric='mlogloss')}\n",
    "    regression_models = {\"Linear Regression\": LinearRegression(),\"Decision Tree Regressor\": DecisionTreeRegressor(),\"Random Forest Regressor\": RandomForestRegressor(),\"SVR\": SVR(),\"KNN Regressor\": KNeighborsRegressor(),\"Ridge Regression\": Ridge(),\"Lasso Regression\": Lasso(),\"XGB Regressor\": XGBRegressor(eval_metric='mlogloss')}\n",
    "    models = classification_models if problem_type == 'classification' else regression_models\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        if problem_type == 'classification':\n",
    "            f1 = f1_score(y_test, predictions, average='macro')\n",
    "            results.append((name, model, f1))\n",
    "            print(f\"Model {name}: \" +f\"Accuracy: {format(accuracy_score(y_test, predictions), '.3f')}| \" +f\"F1 Score avg: {format(f1, '.3f')}| \"+f\"Precision: {format(precision_score(y_test, predictions, average='macro'), '.3f')}| \"+f\"Recall: {format(recall_score(y_test, predictions, average='macro'), '.3f')}\")\n",
    "        else:\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            results.append((name, model, mse))\n",
    "            print(f\"Model {name}: \" +f\"MSE: {format(mse, '.3f')}\")\n",
    "    top_3_models = sorted(results, key=lambda x: x[2], reverse=True)[:3] if problem_type == 'classification' else sorted(results, key=lambda x: x[2])[:3]\n",
    "    return [(name, model) for name, model, _ in top_3_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_spearman(dt):\n",
    "    dt['target_code'] = dt['target'].astype('category').cat.codes\n",
    "    corr_matrixSpear = dt.drop('target', axis=1).corr(method='spearman')\n",
    "    spearman_corr = corr_matrixSpear['target_code'].abs().sort_values(ascending=False)\n",
    "    spearman_corr = spearman_corr.drop('target_code')\n",
    "    dt.drop('target_code', axis=1, inplace=True)\n",
    "    # plt.figure(figsize=(5, 5))\n",
    "    # spearman_corr.plot(kind='bar')\n",
    "    # plt.title('Feature Correlation with Target')\n",
    "    # plt.ylabel('Correlation')\n",
    "    # plt.show()\n",
    "    return spearman_corr.index.tolist()\n",
    "def feature_importance(models, X, y):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    feature_names = X.columns\n",
    "    d = dict()\n",
    "    for name, model in models:\n",
    "        print(f\"Model: {name}\")\n",
    "        model.fit(X, y)\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            names = [feature_names[i] for i in indices]\n",
    "            d.update({name: names})\n",
    "            plt.figure()\n",
    "            plt.title(f\"Feature Importance for {name}\")\n",
    "            plt.barh(range(X.shape[1]), importances[indices])\n",
    "            plt.yticks(range(X.shape[1]), names)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Model does not support feature importance\")\n",
    "    return d\n",
    "def sfs_selector(dt, models, X, y, direction):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    d = dict()\n",
    "    print(f\"{direction.capitalize()} Selection\")\n",
    "    for name, model in models:\n",
    "        sfs = SequentialFeatureSelector(model, n_features_to_select=10, direction=direction)\n",
    "        train, test = train_test_split(dt, test_size=0.2, random_state=4)\n",
    "        N, M = train.shape\n",
    "        M = M - 1\n",
    "        sfs.fit(X, y)\n",
    "        features = sfs.get_support()\n",
    "        seleFeatures = np.arange(M)[features]\n",
    "        seleFeatureNames = train.columns[seleFeatures].append(pd.Index(['target']))\n",
    "        d.update({name: seleFeatureNames})\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tuning_with_scalers(models, param_grid, problem_type):\n",
    "    pipelines = {}\n",
    "    for model_name, (model, X, y) in models.items():\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "        pipelines[f\"{model_name} Standard\"] = (Pipeline([(\"Scaler\", StandardScaler()), (model_name, model)]), X_train, y_train, X_test, y_test)\n",
    "        pipelines[f\"{model_name} MinMax\"] = (Pipeline([(\"Scaler\", MinMaxScaler()), (model_name, model)]), X_train, y_train, X_test, y_test)\n",
    "    tuned_models = {}\n",
    "    scoring_type = \"f1_macro\" if problem_type == 'classification' else \"neg_root_mean_squared_error\"\n",
    "    for pipeline_name, (pipeline, X, y, X_test1, y_test1) in pipelines.items():\n",
    "        search = GridSearchCV(pipeline, param_grid[pipeline_name.split()[0]], n_jobs=-1, scoring=scoring_type)\n",
    "        search.fit(X, y)\n",
    "        best_model = search.best_estimator_\n",
    "        tuned_models[pipeline_name] = {'model': best_model, 'X': X, 'y': y, 'X_test': X_test1, 'y_test': y_test1}\n",
    "        changed_params = {param: value for param, value in best_model.named_steps[pipeline_name.split()[0]].get_params().items() if value != best_model.named_steps[pipeline_name.split()[0]].__class__().get_params()[param]}\n",
    "        print(f\"Pipeline: {pipeline_name},\" f\"Changed Params: {changed_params}, \"f\"Best cv-score: {search.best_score_}\")\n",
    "    return tuned_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(tuned_models, model_name, problem_type):\n",
    "    X_train,y_train = tuned_models[model_name][\"X\"], tuned_models[model_name][\"y\"]\n",
    "    X_test, y_test = tuned_models[model_name][\"X_test\"],tuned_models[model_name][\"y_test\"]\n",
    "    model = tuned_models[model_name][\"model\"]\n",
    "    scaler = model.named_steps['Scaler']\n",
    "    X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.fit_transform(X_test)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    if problem_type == 'classification':\n",
    "        train_accuracy, test_accuracy = accuracy_score(y_train, model.predict(X_train_scaled)), accuracy_score(y_test, y_pred)\n",
    "        print(f\"Model: {model_name}, Train Accuracy: {train_accuracy:.3f}, Test Accuracy: {test_accuracy:.3f}, F1 macro: {f1_score(y_test, y_pred, average='macro'):.3f}, Recall: {recall_score(y_test, y_pred, average='macro'):.3f}\")\n",
    "    else:\n",
    "        print(f\"Model: {model_name}, MSE: {mean_squared_error(y_test, y_pred):.3f}, R2: {model.score(X_test_scaled, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Logistic Regression: Accuracy: 0.845| F1 Score avg: 0.586| Precision: 0.731| Recall: 0.509\n",
      "Model Decision Tree Classifier: Accuracy: 0.929| F1 Score avg: 0.820| Precision: 0.824| Recall: 0.820\n",
      "Model Random Forest Classifier: Accuracy: 0.938| F1 Score avg: 0.841| Precision: 0.882| Recall: 0.814\n",
      "Model SVM: Accuracy: 0.804| F1 Score avg: 0.457| Precision: 0.753| Recall: 0.376\n",
      "Model KNN Classifier: Accuracy: 0.831| F1 Score avg: 0.588| Precision: 0.757| Recall: 0.506\n",
      "Model MLP: Accuracy: 0.897| F1 Score avg: 0.757| Precision: 0.779| Recall: 0.743\n",
      "Model NaiveBayes: Accuracy: 0.075| F1 Score avg: 0.140| Precision: 0.190| Recall: 0.296\n",
      "Model XGB Classifier: Accuracy: 0.948| F1 Score avg: 0.878| Precision: 0.882| Recall: 0.877\n",
      "Forward Selection\n",
      "['age:', 'sex:', 'on thyroxine:', 'thyroid surgery:', 'TSH:', 'T3:', 'TT4:', 'T4U:', 'FTI:', 'TBG:', 'target'] ['on thyroxine:', 'thyroid surgery:', 'TSH:', 'T3 measured:', 'T3:', 'TT4:', 'T4U measured:', 'T4U:', 'FTI:', 'TBG:', 'target'] ['age:', 'on thyroxine:', 'pregnant:', 'thyroid surgery:', 'tumor:', 'TSH:', 'T3:', 'TT4:', 'FTI:', 'TBG:', 'target']\n",
      "Score do DecisionTree: Train acc: 1.000| Test acc 0.931| F1 macro: 0.818| Recall: 0.828\n",
      "Score do RandomForest: Train acc: 1.000| Test acc 0.945| F1 macro: 0.856| Recall: 0.856\n",
      "Score do XGB: Train acc: 1.000| Test acc 0.946| F1 macro: 0.858| Recall: 0.863\n",
      "Pipeline: DecisionTree Standard,Changed Params: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 10}, Best cv-score: 0.8174718272999009\n",
      "Pipeline: DecisionTree MinMax,Changed Params: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5}, Best cv-score: 0.8166835844755734\n",
      "Pipeline: RandomForest Standard,Changed Params: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 250, 'random_state': 4}, Best cv-score: 0.8489562731217596\n",
      "Pipeline: RandomForest MinMax,Changed Params: {'max_depth': 20, 'n_estimators': 200, 'random_state': 4}, Best cv-score: 0.8498925034278212\n",
      "Pipeline: XGB Standard,Changed Params: {'objective': 'multi:softprob', 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'learning_rate': 0.2, 'max_depth': 10, 'missing': nan, 'n_estimators': 200, 'subsample': 0.7}, Best cv-score: 0.8525902256404775\n",
      "Pipeline: XGB MinMax,Changed Params: {'objective': 'multi:softprob', 'colsample_bytree': 1.0, 'eval_metric': 'mlogloss', 'learning_rate': 0.2, 'max_depth': 10, 'missing': nan, 'n_estimators': 200, 'subsample': 0.7}, Best cv-score: 0.8525902256404775\n",
      "Model: DecisionTree Standard, Train Accuracy: 0.969, Test Accuracy: 0.917, F1 macro: 0.805, Recall: 0.846\n",
      "Model: DecisionTree MinMax, Train Accuracy: 0.977, Test Accuracy: 0.525, F1 macro: 0.375, Recall: 0.516\n",
      "Model: RandomForest Standard, Train Accuracy: 0.994, Test Accuracy: 0.927, F1 macro: 0.836, Recall: 0.850\n",
      "Model: RandomForest MinMax, Train Accuracy: 1.000, Test Accuracy: 0.629, F1 macro: 0.428, Recall: 0.575\n",
      "Model: XGB Standard, Train Accuracy: 1.000, Test Accuracy: 0.917, F1 macro: 0.803, Recall: 0.805\n",
      "Model: XGB MinMax, Train Accuracy: 1.000, Test Accuracy: 0.606, F1 macro: 0.428, Recall: 0.580\n"
     ]
    }
   ],
   "source": [
    "dt = dataCreator(\"diagnoses\")\n",
    "best_models = modelCreator(dt, \"classification\")\n",
    "# spear_corr = pearson_spearman(dt)\n",
    "# most_important_features = feature_importance(best_models, dt.drop(\"target\", axis=1), dt[\"target\"])\n",
    "sfs_forward = sfs_selector(dt, best_models, dt.drop(\"target\", axis=1), dt[\"target\"], 'forward')\n",
    "# print(' '.join(name for name, _ in best_models))\n",
    "print(' '.join(str(sfs_forward[key].tolist()) for key in sfs_forward))\n",
    "le = LabelEncoder()\n",
    "dt_tree, dt_forest, dt_xgb = dt.copy(), dt.copy(), dt.copy()\n",
    "tree_best_features = ['sex:','on thyroxine:','thyroid surgery:','tumor:','TSH:','T3:','TT4:','T4U:','FTI:','TBG:',\"target\"]\n",
    "forest_best_features = ['on thyroxine:','pregnant:','thyroid surgery:','TSH:','T3 measured:','T3:','TT4:','T4U:','FTI:','TBG:',\"target\"]\n",
    "xgb_best_features = ['age:','sex:','on thyroxine:','query on thyroxine:','on antithyroid medication:','thyroid surgery:','I131 treatment:','tumor:','psych:','TSH:','T3:','TT4:', 'T4U:','FTI:', 'TBG:',\"target\"]\n",
    "cols_to_drop_tree, cols_to_drop_forest, cols_to_drop_xgb = dt_tree.columns.difference(tree_best_features), dt_forest.columns.difference(forest_best_features), dt_xgb.columns.difference(xgb_best_features)\n",
    "dt_tree, dt_forest, dt_xgb = dt_tree.drop(cols_to_drop_tree, axis=1), dt_forest.drop(cols_to_drop_forest, axis=1), dt_xgb.drop(cols_to_drop_xgb, axis=1)\n",
    "X_tree, X_forest, X_xgb = dt_tree.drop('target', axis=1), dt_forest.drop('target', axis=1), dt_xgb.drop('target', axis=1)\n",
    "y_tree, y_forest, y_xgb = le.fit_transform(dt_tree['target']), le.fit_transform(dt_forest['target']), le.fit_transform(dt_xgb['target'])\n",
    "models = {\"DecisionTree\": (DecisionTreeClassifier(), X_tree, y_tree),\"RandomForest\": (RandomForestClassifier(n_estimators=150,random_state=4), X_forest, y_forest), \"XGB\": (XGBClassifier(eval_metric='mlogloss'), X_xgb, y_xgb)}\n",
    "for model_name, (model, X, y) in models.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_preds,test_preds= model.predict(X_train), model.predict(X_test)\n",
    "    print(f\"Score do {model_name}: Train acc: {format(accuracy_score(y_train, train_preds), '.3f')}| Test acc {format(accuracy_score(y_test, test_preds), '.3f')}| F1 macro: {format(f1_score(y_test, test_preds, average='macro'), '.3f')}| Recall: {format(recall_score(y_test, test_preds, average='macro'), '.3f')}\")\n",
    "param_grid = {\"XGB\": {\"XGB__max_depth\": [10, 15, 25, 30],\"XGB__n_estimators\": [200, 300, 400],\"XGB__learning_rate\": [0.01, 0.1, 0.2],\"XGB__subsample\": [0.7, 0.8, 0.9],\"XGB__colsample_bytree\": [0.5, 0.7, 1.0]},\"RandomForest\": {\"RandomForest__max_depth\": [15, 20, 25],\"RandomForest__n_estimators\": [150, 200, 250],\"RandomForest__min_samples_split\": [2, 5, 10],\"RandomForest__min_samples_leaf\": [1, 2, 5]},\"DecisionTree\": {\"DecisionTree__max_depth\": [15, 20, 25, 30],\"DecisionTree__min_samples_split\": [2, 5, 10],\"DecisionTree__min_samples_leaf\": [1, 2, 5]}}\n",
    "tuned_models = model_tuning_with_scalers(models, param_grid, \"classification\")\n",
    "for name in tuned_models:\n",
    "    evaluate_models(tuned_models, name, \"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Logistic Regression: Accuracy: 0.678| F1 Score avg: 0.543| Precision: 0.640| Recall: 0.562\n",
      "Model Decision Tree Classifier: Accuracy: 0.620| F1 Score avg: 0.566| Precision: 0.569| Recall: 0.565\n",
      "Model Random Forest Classifier: Accuracy: 0.675| F1 Score avg: 0.540| Precision: 0.630| Recall: 0.560\n",
      "Model SVM: Accuracy: 0.670| F1 Score avg: 0.468| Precision: 0.663| Recall: 0.528\n",
      "Model KNN Classifier: Accuracy: 0.646| F1 Score avg: 0.565| Precision: 0.585| Recall: 0.566\n",
      "Model MLP: Accuracy: 0.682| F1 Score avg: 0.602| Precision: 0.636| Recall: 0.601\n",
      "Model NaiveBayes: Accuracy: 0.544| F1 Score avg: 0.544| Precision: 0.604| Recall: 0.604\n",
      "Model XGB Classifier: Accuracy: 0.673| F1 Score avg: 0.596| Precision: 0.623| Recall: 0.595\n",
      "MLP XGB Classifier Decision Tree Classifier\n",
      "Forward Selection\n",
      "['query on thyroxine:', 'on antithyroid medication:', 'pregnant:', 'tumor:', 'psych:', 'T3:', 'T4U measured:', 'T4U:', 'TBG measured:', 'TBG:', 'target'] ['query hyperthyroid:', 'lithium:', 'tumor:', 'hypopituitary:', 'psych:', 'TSH measured:', 'TT4 measured:', 'T4U measured:', 'T4U:', 'FTI measured:', 'target'] ['on thyroxine:', 'pregnant:', 'query hypothyroid:', 'query hyperthyroid:', 'lithium:', 'tumor:', 'hypopituitary:', 'psych:', 'T4U measured:', 'FTI measured:', 'target']\n",
      "Score do DecisionTree: Train acc: 0.684 Test acc 0.682 F1 macro: 0.405Recall: 0.498\n",
      "Score do MLP: Train acc: 0.702 Test acc 0.685 F1 macro: 0.529Recall: 0.547\n",
      "Score do XGB: Train acc: 0.707 Test acc 0.692 F1 macro: 0.521Recall: 0.546\n",
      "Pipeline: DecisionTree Standard, Scaler: StandardScaler, Model: DecisionTreeClassifier, Changed Params: {'max_depth': 5, 'min_samples_split': 10}, Best cv-score: 0.41644861343448153\n",
      "Pipeline: DecisionTree MinMax, Scaler: MinMaxScaler, Model: DecisionTreeClassifier, Changed Params: {'max_depth': 5, 'min_samples_split': 10}, Best cv-score: 0.41644861343448153\n",
      "Pipeline: MLP Standard, Scaler: StandardScaler, Model: MLPClassifier, Changed Params: {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'max_iter': 1000}, Best cv-score: 0.5858209540106991\n",
      "Pipeline: MLP MinMax, Scaler: MinMaxScaler, Model: MLPClassifier, Changed Params: {'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'max_iter': 1000}, Best cv-score: 0.5805268606988088\n",
      "Pipeline: XGB Standard, Scaler: StandardScaler, Model: XGBClassifier, Changed Params: {'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'learning_rate': 0.3, 'max_depth': 5, 'missing': nan, 'n_estimators': 200, 'subsample': 0.5}, Best cv-score: 0.5394398844692349\n",
      "Pipeline: XGB MinMax, Scaler: MinMaxScaler, Model: XGBClassifier, Changed Params: {'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'learning_rate': 0.3, 'max_depth': 5, 'missing': nan, 'n_estimators': 200, 'subsample': 0.5}, Best cv-score: 0.5394398844692349\n",
      "Model: DecisionTree Standard, Train Accuracy: 0.691, Test Accuracy: 0.656, F1 macro: 0.400, Recall: 0.500\n",
      "Model: DecisionTree MinMax, Train Accuracy: 0.691, Test Accuracy: 0.656, F1 macro: 0.400, Recall: 0.500\n",
      "Model: MLP Standard, Train Accuracy: 0.711, Test Accuracy: 0.677, F1 macro: 0.572, Recall: 0.578\n",
      "Model: MLP MinMax, Train Accuracy: 0.709, Test Accuracy: 0.676, F1 macro: 0.577, Recall: 0.582\n",
      "Model: XGB Standard, Train Accuracy: 0.710, Test Accuracy: 0.656, F1 macro: 0.508, Recall: 0.536\n",
      "Model: XGB MinMax, Train Accuracy: 0.710, Test Accuracy: 0.668, F1 macro: 0.538, Recall: 0.556\n"
     ]
    }
   ],
   "source": [
    "dt = dataCreator(\"sex:\")\n",
    "le = LabelEncoder()\n",
    "best_models = modelCreator(dt, \"classification\")\n",
    "print(' '.join(name for name, _ in best_models))\n",
    "# spear_corr = pearson_spearman(dt)\n",
    "# most_important_features = feature_importance(best_models, dt.drop(\"target\", axis=1), dt[\"target\"])\n",
    "sfs_forward = sfs_selector(dt, best_models, dt.drop(\"target\", axis=1), dt[\"target\"], 'forward')\n",
    "print(' '.join(str(sfs_forward[key].tolist()) for key in sfs_forward))\n",
    "xgb_best_features = [\"T4U:\",\"pregnant:\",\"on thyroxine:\",\"T4U measured:\",\"TT4 measured:\",\"on thyroxine:\",\"query hyperthyroid:\",\"tumor:\",\"psych:\",\"TBG measured:\", \"target\"]\n",
    "tree_best_features = [\"on thyroxine:\",\"on antithyroid medication:\",\"query hyperthyroid:\",\"query hypothyroid:\",\"tumor\",\"psych\",\"TSH measured:\",\"T4U measured:\",\"FTI measured:\", \"target\"]\n",
    "mlp_best_features = ['on thyroxine:','query on thyroxine:','thyroid surgery:','tumor:','hypopituitary:','psych:','TSH measured:','T3 measured:','T3:','T4U:','TBG measured:','TBG:','diagnoses', \"target\"]\n",
    "dt_tree, dt_mlp, dt_xgb = dt.copy(), dt.copy(), dt.copy()\n",
    "cols_to_drop_tree, cols_to_drop_mlp, cols_to_drop_xgb = dt_tree.columns.difference(tree_best_features), dt_mlp.columns.difference(mlp_best_features), dt_xgb.columns.difference(xgb_best_features)\n",
    "dt_tree, dt_mlp, dt_xgb = dt_tree.drop(cols_to_drop_tree, axis=1), dt_mlp.drop(cols_to_drop_mlp, axis=1), dt_xgb.drop(cols_to_drop_xgb, axis=1)\n",
    "X_tree, X_mlp, X_xgb = dt_tree.drop('target', axis=1), dt_mlp.drop('target', axis=1), dt_xgb.drop('target', axis=1)\n",
    "y_tree, y_mlp, y_xgb = le.fit_transform(dt_tree['target']), le.fit_transform(dt_mlp['target']), le.fit_transform(dt_xgb['target'])\n",
    "models = {\"DecisionTree\": (DecisionTreeClassifier(), X_tree, y_tree),\"MLP\": (MLPClassifier(max_iter=1000), X_mlp, y_mlp),\"XGB\": (XGBClassifier(eval_metric='mlogloss'), X_xgb, y_xgb),}\n",
    "for model_name, (model, X, y) in models.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_preds,test_preds= model.predict(X_train), model.predict(X_test)\n",
    "    print(f\"Score do {model_name}: Train acc: {format(accuracy_score(y_train, train_preds), '.3f')} Test acc {format(accuracy_score(y_test, test_preds), '.3f')} F1 macro: {format(f1_score(y_test, test_preds, average='macro'), '.3f')}Recall: {format(recall_score(y_test, test_preds, average='macro'), '.3f')}\")\n",
    "param_grid = {\"DecisionTree\": {\"DecisionTree__max_depth\": [5, 10, 15, 20, 25, 30],\"DecisionTree__min_samples_split\": [2, 5, 10],\"DecisionTree__min_samples_leaf\": [1, 2, 4]},\"MLP\": {\"MLP__hidden_layer_sizes\": [(50,50,50), (50,100,50), (100,)],\"MLP__activation\": ['tanh', 'relu'],\"MLP__solver\": ['sgd', 'adam'],\"MLP__alpha\": [0.0001, 0.05],\"MLP__learning_rate\": ['constant','adaptive'],},\"XGB\": {\"XGB__max_depth\": [5, 10, 15, 20, 25, 30],\"XGB__n_estimators\": [100, 150, 200],\"XGB__learning_rate\": [0.01, 0.1, 0.2, 0.3],\"XGB__subsample\": [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\"XGB__colsample_bytree\": [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}}\n",
    "tuned_models = model_tuning_with_scalers(models, param_grid, \"classification\")\n",
    "for name in tuned_models:\n",
    "    evaluate_models(tuned_models, name, \"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Linear Regression: MSE: 316.904\n",
      "Model Decision Tree Regressor: MSE: 643.062\n",
      "Model Random Forest Regressor: MSE: 343.446\n",
      "Model SVR: MSE: 315.242\n",
      "Model KNN Regressor: MSE: 364.113\n",
      "Model Ridge Regression: MSE: 316.860\n",
      "Model Lasso Regression: MSE: 331.007\n",
      "Model XGB Regressor: MSE: 346.126\n",
      "SVR Ridge Regression Linear Regression\n",
      "Forward Selection\n",
      "['on antithyroid medication:', 'sick:', 'pregnant:', 'thyroid surgery:', 'I131 treatment:', 'goitre:', 'psych:', 'TSH measured:', 'T3:', 'T4U:', 'target'] ['sick:', 'pregnant:', 'I131 treatment:', 'psych:', 'TSH measured:', 'T3 measured:', 'T3:', 'TT4:', 'T4U:', 'FTI:', 'target'] ['sick:', 'pregnant:', 'I131 treatment:', 'psych:', 'TSH measured:', 'T3 measured:', 'T3:', 'TT4:', 'T4U:', 'FTI:', 'target']\n",
      "R^2: 0.08525374104362526 | MSE: 321.76644057439194\n",
      "R^2: 0.08587947202577839 | MSE: 321.5463366615165\n",
      "R^2: 0.08594919872774098 | MSE: 321.5218099553574\n",
      "Pipeline: SVR Standard, Scaler: StandardScaler, Model: SVR, Changed Params: {'gamma': 1}, Best cv-score: -18.087899011704035\n",
      "Pipeline: SVR MinMax, Scaler: MinMaxScaler, Model: SVR, Changed Params: {'C': 10, 'gamma': 10}, Best cv-score: -18.24936810248889\n",
      "Pipeline: Linear Standard, Scaler: StandardScaler, Model: LinearRegression, Changed Params: {}, Best cv-score: -17.99214939801764\n",
      "Pipeline: Linear MinMax, Scaler: MinMaxScaler, Model: LinearRegression, Changed Params: {}, Best cv-score: -17.99214939801764\n",
      "Pipeline: Ridge Standard, Scaler: StandardScaler, Model: Ridge, Changed Params: {'alpha': 10, 'solver': 'lsqr'}, Best cv-score: -17.99161665514962\n",
      "Pipeline: Ridge MinMax, Scaler: MinMaxScaler, Model: Ridge, Changed Params: {'alpha': 0.01, 'max_iter': 100, 'solver': 'sag'}, Best cv-score: -17.992086000765404\n",
      "Model: SVR Standard, MSE: 320.181, R2: 0.057\n",
      "Model: SVR MinMax, MSE: 335.875, R2: 0.011\n",
      "Model: Linear Standard, MSE: 318.309, R2: 0.062\n",
      "Model: Linear MinMax, MSE: 343.551, R2: -0.012\n",
      "Model: Ridge Standard, MSE: 318.148, R2: 0.063\n",
      "Model: Ridge MinMax, MSE: 343.470, R2: -0.012\n"
     ]
    }
   ],
   "source": [
    "dt = dataCreator(\"age:\")\n",
    "le = LabelEncoder()\n",
    "best_models = modelCreator(dt, \"regression\")\n",
    "print(' '.join(name for name, _ in best_models))\n",
    "# spear_corr = pearson_spearman(dt)\n",
    "# most_important_features = feature_importance(best_models, dt.drop(\"target\", axis=1), dt[\"target\"])\n",
    "sfs_forward = sfs_selector(dt, best_models, dt.drop(\"target\", axis=1), dt[\"target\"], 'forward')\n",
    "print(' '.join(str(sfs_forward[key].tolist()) for key in sfs_forward))\n",
    "svr_best_features = ['query on thyroxine:', 'on antithyroid medication:', 'sick:','pregnant:', 'thyroid surgery:', 'I131 treatment:', 'lithium:','goitre:', 'tumor:', 'hypopituitary:', 'psych:', 'TSH measured:', 'T3:','T4U:', 'TBG measured:', 'target']\n",
    "linear_best_features = ['on antithyroid medication:', 'sick:', 'pregnant:', 'thyroid surgery:','I131 treatment:', 'lithium:', 'goitre:', 'psych:', 'TSH measured:','T3 measured:', 'T3:', 'TT4:', 'T4U:', 'FTI:', 'TBG:', 'target']\n",
    "ridge_best_features = ['on antithyroid medication:', 'sick:', 'pregnant:', 'thyroid surgery:','I131 treatment:', 'lithium:', 'goitre:', 'psych:', 'TSH measured:','T3 measured:', 'T3:', 'TT4:', 'T4U:', 'FTI:', 'TBG:', 'target']\n",
    "dt_svr, dt_linear, dt_ridge = dt.copy(), dt.copy(), dt.copy()\n",
    "cols_to_drop_svr, cols_to_drop_linear, cols_to_drop_ridge = dt_svr.columns.difference(svr_best_features), dt_linear.columns.difference(linear_best_features), dt_ridge.columns.difference(ridge_best_features)\n",
    "dt_svr, dt_linear, dt_ridge = dt_svr.drop(cols_to_drop_svr, axis=1), dt_linear.drop(cols_to_drop_linear, axis=1), dt_ridge.drop(cols_to_drop_ridge, axis=1)\n",
    "X_svr, X_linear, X_ridge = dt_svr.drop('target', axis=1), dt_linear.drop('target', axis=1), dt_ridge.drop('target', axis=1)\n",
    "y_svr, y_linear, y_ridge = le.fit_transform(dt_svr['target']), le.fit_transform(dt_linear['target']), le.fit_transform(dt_ridge['target'])\n",
    "models = {\"SVR\": (SVR(), X_svr, y_svr),\"Linear\": (LinearRegression(), X_linear, y_linear),\"Ridge\": (Ridge(), X_ridge, y_ridge),}\n",
    "for model_name, (model, X, y) in models.items():\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f'R^2: {model.score(X_test, y_test)} | MSE: {mean_squared_error(y_test, y_pred)}')\n",
    "param_grid = {\"SVR\": {'SVR__kernel': ['linear', 'rbf'],'SVR__C': [0.1, 1, 10, 100, 1000],'SVR__gamma': ['scale', 'auto', 0.1, 1, 10]},\"Linear\": {\"Linear__fit_intercept\": [True, False],\"Linear__copy_X\": [True, False],\"Linear__n_jobs\": [None, 1, 2, 3, 4, 5],\"Linear__positive\": [True, False],},\"Ridge\": {'Ridge__alpha': [0.01, 0.1, 1, 10, 100],'Ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],'Ridge__fit_intercept': [True, False],'Ridge__copy_X': [True, False],'Ridge__max_iter': [None, 100, 1000, 5000],'Ridge__positive': [True, False],},}\n",
    "tuned_models = model_tuning_with_scalers(models, param_grid, \"regression\")\n",
    "for name in tuned_models:\n",
    "    evaluate_models(tuned_models, name, \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest, Accuracy: 0.750, F1 Score avg: 0.429, Precision: 0.375, Recall: 0.500\n",
      "Model: DecisionTree, Accuracy: 0.500, F1 Score avg: 0.222, Precision: 0.222, Recall: 0.222\n",
      "Model: DecisionTree, Accuracy: 0.500, F1 Score avg: 0.222, Precision: 0.167, Recall: 0.333\n",
      "Model: MLP, Accuracy: 0.500, F1 Score avg: 0.222, Precision: 0.167, Recall: 0.333\n",
      "Model: Ridge, MSE: 14.814, RMSE: 3.8488956563790184, R2: -0.185\n",
      "Model: Linear, MSE: 13.566, RMSE: 3.683245772561509, R2: -0.085\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "conditions = {(\"A\", \"B\", \"C\", \"D\"): \"hyperthyroid condition\", (\"E\", \"F\", \"G\", \"H\"): \"hypothyroid condition\", (\"I\", \"J\"): \"binding protein\", (\"K\"): \"general health\", (\"L\", \"M\", \"N\"): \"replacement therapy\",(\"O\", \"P\", \"Q\", \"S\", \"T\"): \"other\",(\"R\"): \"discordant results\", (\"-\"): \"healthy\"}\n",
    "def create_target(verdict):\n",
    "    if len(verdict) == 1:\n",
    "        for key in conditions:\n",
    "            if verdict in key:\n",
    "                return conditions[key]\n",
    "        return \"invalid verdict\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "def dataCreator(targetColumun, dt1, dt2):\n",
    "    dt1 = pd.read_csv(dt1)\n",
    "    dt2 = pd.read_csv(dt2)\n",
    "    dt = pd.concat([dt1, dt2], axis=1)\n",
    "    dt = dt.replace('?',np.nan)\n",
    "    mColumns = ['TSH:', 'T3:', 'TT4:', \"T4U:\", \"FTI:\", \"TBG:\"]\n",
    "    dt[\"diagnoses\"] = dt[\"diagnoses\"].apply(create_target)\n",
    "    le = LabelEncoder()\n",
    "    if targetColumun != \"diagnoses\":\n",
    "        dt['diagnoses'] = le.fit_transform(dt['diagnoses'])\n",
    "    dt[\"target\"] = dt[targetColumun]\n",
    "    dt = dt.drop([targetColumun, \"referral source:\", \"[record identification]\"], axis=1)\n",
    "    dt = dt.replace({ \"f\": 0, \"t\": 1, \"F\":0, \"M\":1})\n",
    "    for column in mColumns:\n",
    "        dt[column] = pd.to_numeric(dt[column], errors='coerce')\n",
    "    numeric_columns = dt.select_dtypes(include=[np.number])\n",
    "    dt[numeric_columns.columns] = numeric_columns.fillna(-1)\n",
    "    return dt\n",
    "def evaluate_models(tuned_models, problem_type):\n",
    "    for model_name, (model, X, y, scaler) in tuned_models.items():\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "        X_scaled_train = scaler.fit_transform(X_train)\n",
    "        X_scaled_test = scaler.transform(X_test)\n",
    "        model.fit(X_scaled_train, y_train)\n",
    "        y_pred = model.predict(X_scaled_test)\n",
    "        if problem_type == 'regression':\n",
    "            print(f\"Model: {model_name}, MSE: {mean_squared_error(y_test, y_pred):.3f}, RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}, R2: {model.score(X_scaled_test, y_test):.3f}\")\n",
    "        else:\n",
    "            print(f\"Model: {model_name}, Accuracy: {accuracy_score(y_test, y_pred):.3f}, F1 Score avg: {f1_score(y_test, y_pred, average='macro'):.3f}, Precision: {precision_score(y_test, y_pred, average='macro'):.3f}, Recall: {recall_score(y_test, y_pred, average='macro'):.3f}\")\n",
    "o1 = dataCreator(\"diagnoses\", \"proj-test-data.csv\", \"proj-test-class.csv\")\n",
    "o2 = dataCreator(\"sex:\",\"proj-test-data.csv\", \"proj-test-class.csv\")\n",
    "o2age = dataCreator(\"age:\",\"proj-test-data.csv\", \"proj-test-class.csv\")\n",
    "def testO1(dt):\n",
    "    le = LabelEncoder()\n",
    "    dt_tree, dt_forest = dt.copy(), dt.copy()\n",
    "    tree_best_features = ['sex:','on thyroxine:','thyroid surgery:','tumor:','TSH:','T3:','TT4:','T4U:','FTI:','TBG:',\"target\"]\n",
    "    forest_best_features = ['on thyroxine:','pregnant:','thyroid surgery:','TSH:','T3 measured:','T3:','TT4:','T4U:','FTI:','TBG:',\"target\"]\n",
    "    cols_to_drop_tree, cols_to_drop_forest = dt_tree.columns.difference(tree_best_features), dt_forest.columns.difference(forest_best_features)\n",
    "    dt_tree, dt_forest = dt_tree.drop(cols_to_drop_tree, axis=1), dt_forest.drop(cols_to_drop_forest, axis=1)\n",
    "    X_tree, X_forest  = dt_tree.drop('target', axis=1), dt_forest.drop('target', axis=1)\n",
    "    y_tree, y_forest = le.fit_transform(dt_tree['target']), le.fit_transform(dt_forest['target'])\n",
    "    tuned_models = {\"RandomForest\": (RandomForestClassifier(max_depth=20, min_samples_split=5, n_estimators=250, random_state=4), X_forest, y_forest, StandardScaler()), \"DecisionTree\": (DecisionTreeClassifier(max_depth=30, min_samples_leaf=2, min_samples_split=10), X_tree, y_tree, StandardScaler())}\n",
    "    evaluate_models(tuned_models, \"classification\")\n",
    "def testO2sex(dt):\n",
    "    le = LabelEncoder()\n",
    "    tree_best_features = [\"on thyroxine:\",\"on antithyroid medication:\",\"query hyperthyroid:\",\"query hypothyroid:\",\"tumor\",\"psych\",\"TSH measured:\",\"T4U measured:\",\"FTI measured:\", \"target\"]\n",
    "    mlp_best_features = ['on thyroxine:','query on thyroxine:','thyroid surgery:','tumor:','hypopituitary:','psych:','TSH measured:','T3 measured:','T3:','T4U:','TBG measured:','TBG:','diagnoses', \"target\"]\n",
    "    dt_tree, dt_mlp = dt.copy(), dt.copy()\n",
    "    cols_to_drop_tree, cols_to_drop_mlp = dt_tree.columns.difference(tree_best_features), dt_mlp.columns.difference(mlp_best_features)\n",
    "    dt_tree, dt_mlp = dt_tree.drop(cols_to_drop_tree, axis=1), dt_mlp.drop(cols_to_drop_mlp, axis=1)\n",
    "    X_tree, X_mlp = dt_tree.drop('target', axis=1), dt_mlp.drop('target', axis=1)\n",
    "    y_tree, y_mlp = le.fit_transform(dt_tree['target']), le.fit_transform(dt_mlp['target'])\n",
    "    tuned_models = {\"DecisionTree\": (DecisionTreeClassifier(max_depth=5, min_samples_split=10), X_tree, y_tree, StandardScaler()),\"MLP\":(MLPClassifier(alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate='adaptive', max_iter=1000), X_mlp, y_mlp, MinMaxScaler())}\n",
    "    evaluate_models(tuned_models, \"classification\")\n",
    "def testO3age(dt):\n",
    "    le = LabelEncoder()\n",
    "    linear_best_features = ['on antithyroid medication:', 'sick:', 'pregnant:', 'thyroid surgery:','I131 treatment:', 'lithium:', 'goitre:', 'psych:', 'TSH measured:','T3 measured:', 'T3:', 'TT4:', 'T4U:', 'FTI:', 'TBG:', 'target']\n",
    "    ridge_best_features = ['on antithyroid medication:', 'sick:', 'pregnant:', 'thyroid surgery:','I131 treatment:', 'lithium:', 'goitre:', 'psych:', 'TSH measured:','T3 measured:', 'T3:', 'TT4:', 'T4U:', 'FTI:', 'TBG:', 'target']\n",
    "    dt_linear, dt_ridge = dt.copy(), dt.copy()\n",
    "    cols_to_drop_linear, cols_to_drop_ridge = dt_linear.columns.difference(linear_best_features), dt_ridge.columns.difference(ridge_best_features)\n",
    "    dt_linear, dt_ridge = dt_linear.drop(cols_to_drop_linear, axis=1), dt_ridge.drop(cols_to_drop_ridge, axis=1)\n",
    "    X_linear, X_ridge = dt_linear.drop('target', axis=1), dt_ridge.drop('target', axis=1)\n",
    "    y_linear, y_ridge = le.fit_transform(dt_linear['target']), le.fit_transform(dt_ridge['target'])\n",
    "    tuned_models = {\"Ridge\" : (Ridge(alpha=10, solver='lsqr'),X_ridge, y_ridge, StandardScaler()), \"Linear\":(LinearRegression(), X_linear, y_linear, StandardScaler())}\n",
    "    evaluate_models(tuned_models, 'regression')\n",
    "testO1(o1)\n",
    "testO2sex(o2)\n",
    "testO3age(o2age)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
